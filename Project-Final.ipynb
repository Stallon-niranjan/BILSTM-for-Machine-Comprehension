{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INKERS EIP : End-to-End Deep Learning Project \n",
    "| Intern Name: Niranjan Anandakumar          |  Batch A | nirunitk@gmail.com | +91-9833499066 | \n",
    "\n",
    "LinkedIn : https://www.linkedin.com/in/niranjanaryan/\n",
    "### Project Description\n",
    "A Blog on Implementation of Research Paper by Yuanfudao and Team Released in March 2018 , latest Release in May  2018\n",
    "\n",
    "## SemEval-2018 Task 11: Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension\n",
    "\n",
    "Authors : Liang Wang, Meng Sun, Wei Zhao, Kewei Shen, Jingming Liu, from Yuanfudao Research Beijing China\n",
    "\n",
    "email { wangliang01,sunmeng,zhaowei01,shenkw,liujm } @fenbi.com\n",
    "\n",
    "#### Model Overview\n",
    "We use Attention-Based LSTM Networks.\n",
    "For more technical details, please refer to our paper at https://arxiv.org/abs/1803.00191\n",
    "\n",
    "For more details about this task, please refer to paper SemEval-2018 Task 11: Machine Comprehension Using Commonsense Knowledge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages Prerequisite\n",
    "\n",
    "python 3.5\n",
    "\n",
    "pytorch >= 0.2\n",
    "\n",
    "spacy >= 2.0\n",
    "\n",
    "#### GPU machine is preferred, training on CPU will be much slower.\n",
    "\n",
    "### 1. Data Collection and Preparation\n",
    "\n",
    "Download preprocessed data from [Google Drive](https://drive.google.com/open?id=1M1saVYk-4Xh0Y0Ok6e8liDLnElnGc0P4) or [Baidu Cloud Disk](https://pan.baidu.com/s/1kWHj2z9), unzip and put them under folder data/.\n",
    "\n",
    "If you choose to preprocess dataset by yourself,\n",
    "please preprocess official dataset by `python3 preprocess.py`, download [Glove embeddings](http://nlp.stanford.edu/data/glove.840B.300d.zip),\n",
    "and also remember to download [ConceptNet](https://github.com/commonsense/conceptnet5/wiki/Downloads) and preprocess it with \n",
    "`python3 preprocess.py conceptnet`\n",
    "\n",
    "Official dataset can be downloaded on [hidrive](https://my.hidrive.com/lnk/DhAhE8B5).\n",
    "\n",
    "We transform original XML format data to Json format with [xml2json](https://github.com/hay/xml2json) by running `./xml2json.py --pretty --strip_text -t xml2json -o test-data.json test-data.xml`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building an Architechture \n",
    "\n",
    "The overall model architecture is shown below:\n",
    "\n",
    "![Three-way Attentive Networks](TriAN.jpg)\n",
    "\n",
    "In this paper, we present Three-way Attentive Networks(TriAN) for multiple-choice commonsense reading comprehension.\n",
    "\n",
    "The given task requires modeling interactions between the passage, question and answers. Different questions need to\n",
    "focus on different parts of the passage, attention mechanism is a natural choice and turns out to be effective for \n",
    "reading comprehension.\n",
    "\n",
    "Due to the relatively  small  size  of  training  data, TriAN use word-level attention and \n",
    "consists of only one layer of LSTM(Hochreiter and Schmidhuber, 1997). Deeper models result in serious overfitting and\n",
    "poor generalization empirically. To explicitly model commonsense knowledge, relation embeddings based on ConceptNet(Speeret al.,2017)\n",
    "are   used   as   additional   features.\n",
    "\n",
    "\n",
    "ConceptNet is a large-scale graph of general knowledge from both crowdsourced resources and expert-created resources. \n",
    "It  consists  of  over 21 million edges and 8 million nodes. ConceptNet shows state-of-the-art performance on tasks like\n",
    "word analogy and word relatedness.\n",
    "\n",
    "Besides, We also find that pretraining our network on other datasets helps to improve the overall performance. There  are  some  existing  multiple-choice English reading comprehension datasets contributed by NLP community such as MCTest(Richardson et al., 2013) and RACE(Lai et al.,2017). \n",
    "\n",
    "Although those datasets donâ€™t focus specifically on commonsense comprehension, they provide a convenient way for data augmentation.\n",
    "Augmented data can be used to learn shared regularities of reading comprehension tasks. Combining all of the aforementioned techniques,\n",
    "our system  achieves  competitive  performance on the official test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys; sys.argv=['']; del sys\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We build a Configuration for the Model and most important Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, doc_layers=1, dropout_emb=0.4, dropout_rnn_output=0.4, embedding_file='./data/glove.840B.300d.txt', epoch=1, finetune_topk=10, gpu='0', grad_clipping=10.0, hidden_size=96, lr=0.002, ner_emb_dim=8, optimizer='adamax', pos_emb_dim=12, pretrained='', rel_emb_dim=10, rnn_padding=True, rnn_type='lstm', seed=1234, test_mode=False, use_cuda=True)\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in ('yes', 'true', 't', '1', 'y')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.register('type', 'bool', str2bool)\n",
    "parser.add_argument('--gpu', type=str, default='0', help='GPU to use')\n",
    "parser.add_argument('--epoch', type=int, default=1, help='Number of epoches to run')\n",
    "parser.add_argument('--optimizer', type=str, default='adamax', help='optimizer, adamax or sgd')\n",
    "parser.add_argument('--use_cuda', type='bool', default=True, help='use cuda or not')\n",
    "parser.add_argument('--grad_clipping', type=float, default=10.0, help='maximum L2 norm for gradient clipping')\n",
    "parser.add_argument('--lr', type=float, default=2e-3, help='learning rate')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size')\n",
    "parser.add_argument('--embedding_file', type=str, default='./data/glove.840B.300d.txt', help='embedding file')\n",
    "parser.add_argument('--hidden_size', type=int, default=96, help='default size for RNN layer')\n",
    "parser.add_argument('--doc_layers', type=int, default=1, help='number of RNN layers for doc encoding')\n",
    "parser.add_argument('--rnn_type', type=str, default='lstm', help='RNN type, lstm or gru')\n",
    "parser.add_argument('--dropout_rnn_output', type=float, default=0.4, help='dropout for RNN output')\n",
    "parser.add_argument('--rnn_padding', type='bool', default=True, help='Use padding or not')\n",
    "parser.add_argument('--dropout_emb', type=float, default=0.4, help='dropout rate for embeddings')\n",
    "parser.add_argument('--pretrained', type=str, default='', help='pretrained model path')\n",
    "parser.add_argument('--finetune_topk', type=int, default=10, help='Finetune topk embeddings during training')\n",
    "parser.add_argument('--pos_emb_dim', type=int, default=12, help='Embedding dimension for part-of-speech')\n",
    "parser.add_argument('--ner_emb_dim', type=int, default=8, help='Embedding dimension for named entities')\n",
    "parser.add_argument('--rel_emb_dim', type=int, default=10, help='Embedding dimension for ConceptNet relations')\n",
    "parser.add_argument('--seed', type=int, default=1234, help='random seed')\n",
    "parser.add_argument('--test_mode', type='bool', default=False, help='In test mode, validation data will be used for training')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args)\n",
    "\n",
    "if args.pretrained:\n",
    "    assert all(os.path.exists(p) for p in args.pretrained.split(',')), 'Checkpoint %s does not exist.' % args.pretrained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Utills for the Pytorch model to Be Defined \n",
    "# NLP for Tokensize and  Prepare the bog of word for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 657367 triples from ./data/concept.filter\n"
     ]
    }
   ],
   "source": [
    "from conceptnet import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 1020 examples from ./data/trial-data-processed.json...\n",
      "Load 19462 examples from ./data/train-data-processed.json...\n",
      "Load 2822 examples from ./data/dev-data-processed.json...\n",
      "Load 5594 examples from ./data/test-data-processed.json...\n",
      "Load vocabulary from ./data/vocab...\n",
      "Vocabulary size: 33382\n",
      "Load pos vocabulary from ./data/pos_vocab...\n",
      "POS vocabulary size: 51\n",
      "Load ner vocabulary from ./data/ner_vocab...\n",
      "NER vocabulary size: 20\n",
      "Load relation vocabulary from ./data/rel_vocab...\n",
      "Rel vocabulary size: 39\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import wikiwords\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "words = frozenset(stopwords.words('english'))\n",
    "punc = frozenset(string.punctuation)\n",
    "def is_stopword(w):\n",
    "    return w.lower() in words\n",
    "\n",
    "def is_punc(c):\n",
    "    return c in punc\n",
    "\n",
    "baseline = wikiwords.freq('the')\n",
    "def get_idf(w):\n",
    "    return np.log(baseline / (wikiwords.freq(w.lower()) + 1e-10))\n",
    "\n",
    "def load_data(path):\n",
    "    from doc import Example\n",
    "    data = []\n",
    "    for line in open(path, 'r', encoding='utf-8'):\n",
    "        if path.find('race') < 0 or np.random.random() < 0.6:\n",
    "            data.append(Example(json.loads(line)))\n",
    "    print('Load %d examples from %s...' % (len(data), path))\n",
    "    return data\n",
    "\n",
    "class Dictionary(object):\n",
    "    NULL = '<NULL>'\n",
    "    UNK = '<UNK>'\n",
    "    START = 2\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(token):\n",
    "        return unicodedata.normalize('NFD', token)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tok2ind = {self.NULL: 0, self.UNK: 1}\n",
    "        self.ind2tok = {0: self.NULL, 1: self.UNK}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tok2ind)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.tok2ind)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        if type(key) == int:\n",
    "            return key in self.ind2tok\n",
    "        elif type(key) == str:\n",
    "            return self.normalize(key) in self.tok2ind\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if type(key) == int:\n",
    "            return self.ind2tok.get(key, self.UNK)\n",
    "        if type(key) == str:\n",
    "            return self.tok2ind.get(self.normalize(key),\n",
    "                                    self.tok2ind.get(self.UNK))\n",
    "\n",
    "    def __setitem__(self, key, item):\n",
    "        if type(key) == int and type(item) == str:\n",
    "            self.ind2tok[key] = item\n",
    "        elif type(key) == str and type(item) == int:\n",
    "            self.tok2ind[key] = item\n",
    "        else:\n",
    "            raise RuntimeError('Invalid (key, item) types.')\n",
    "\n",
    "    def add(self, token):\n",
    "        token = self.normalize(token)\n",
    "        if token not in self.tok2ind:\n",
    "            index = len(self.tok2ind)\n",
    "            self.tok2ind[token] = index\n",
    "            self.ind2tok[index] = token\n",
    "\n",
    "    def tokens(self):\n",
    "        \"\"\"Get dictionary tokens.\n",
    "\n",
    "        Return all the words indexed by this dictionary, except for special\n",
    "        tokens.\n",
    "        \"\"\"\n",
    "        tokens = [k for k in self.tok2ind.keys()\n",
    "                  if k not in {'<NULL>', '<UNK>'}]\n",
    "        return tokens\n",
    "\n",
    "vocab, pos_vocab, ner_vocab, rel_vocab = Dictionary(), Dictionary(), Dictionary(), Dictionary()\n",
    "def gen_race_vocab(data):\n",
    "    race_vocab = Dictionary()\n",
    "    build_vocab()\n",
    "    cnt = Counter()\n",
    "    for ex in data:\n",
    "        cnt += Counter(ex.passage.split())\n",
    "        cnt += Counter(ex.question.split())\n",
    "        cnt += Counter(ex.choice.split())\n",
    "    for key, val in cnt.most_common(30000):\n",
    "        if key not in vocab:\n",
    "            race_vocab.add(key)\n",
    "    print('Vocabulary size: %d' % len(race_vocab))\n",
    "    writer = open('./data/race_vocab', 'w', encoding='utf-8')\n",
    "    writer.write('\\n'.join(race_vocab.tokens()))\n",
    "    writer.close()\n",
    "\n",
    "def build_vocab(data=None):\n",
    "    global vocab, pos_vocab, ner_vocab, rel_vocab\n",
    "    # build word vocabulary\n",
    "    if os.path.exists('./data/vocab'):\n",
    "        print('Load vocabulary from ./data/vocab...')\n",
    "        for w in open('./data/vocab', encoding='utf-8'):\n",
    "            vocab.add(w.strip())\n",
    "        print('Vocabulary size: %d' % len(vocab))\n",
    "    else:\n",
    "        cnt = Counter()\n",
    "        for ex in data:\n",
    "            cnt += Counter(ex.passage.split())\n",
    "            cnt += Counter(ex.question.split())\n",
    "            cnt += Counter(ex.choice.split())\n",
    "        for key, val in cnt.most_common():\n",
    "            vocab.add(key)\n",
    "        print('Vocabulary size: %d' % len(vocab))\n",
    "        writer = open('./data/vocab', 'w', encoding='utf-8')\n",
    "        writer.write('\\n'.join(vocab.tokens()))\n",
    "        writer.close()\n",
    "    # build part-of-speech vocabulary\n",
    "    if os.path.exists('./data/pos_vocab'):\n",
    "        print('Load pos vocabulary from ./data/pos_vocab...')\n",
    "        for w in open('./data/pos_vocab', encoding='utf-8'):\n",
    "            pos_vocab.add(w.strip())\n",
    "        print('POS vocabulary size: %d' % len(pos_vocab))\n",
    "    else:\n",
    "        cnt = Counter()\n",
    "        for ex in data:\n",
    "            cnt += Counter(ex.d_pos)\n",
    "            cnt += Counter(ex.q_pos)\n",
    "        for key, val in cnt.most_common():\n",
    "            if key: pos_vocab.add(key)\n",
    "        print('POS vocabulary size: %d' % len(pos_vocab))\n",
    "        writer = open('./data/pos_vocab', 'w', encoding='utf-8')\n",
    "        writer.write('\\n'.join(pos_vocab.tokens()))\n",
    "        writer.close()\n",
    "    # build named entity vocabulary\n",
    "    if os.path.exists('./data/ner_vocab'):\n",
    "        print('Load ner vocabulary from ./data/ner_vocab...')\n",
    "        for w in open('./data/ner_vocab', encoding='utf-8'):\n",
    "            ner_vocab.add(w.strip())\n",
    "        print('NER vocabulary size: %d' % len(ner_vocab))\n",
    "    else:\n",
    "        cnt = Counter()\n",
    "        for ex in data:\n",
    "            cnt += Counter(ex.d_ner)\n",
    "        for key, val in cnt.most_common():\n",
    "            if key: ner_vocab.add(key)\n",
    "        print('NER vocabulary size: %d' % len(ner_vocab))\n",
    "        writer = open('./data/ner_vocab', 'w', encoding='utf-8')\n",
    "        writer.write('\\n'.join(ner_vocab.tokens()))\n",
    "        writer.close()\n",
    "    # Load conceptnet relation vocabulary\n",
    "    assert os.path.exists('./data/rel_vocab')\n",
    "    print('Load relation vocabulary from ./data/rel_vocab...')\n",
    "    for w in open('./data/rel_vocab', encoding='utf-8'):\n",
    "        rel_vocab.add(w.strip())\n",
    "    print('Rel vocabulary size: %d' % len(rel_vocab))\n",
    "\n",
    "def gen_submission(data, prediction):\n",
    "    assert len(data) == len(prediction)\n",
    "    writer = open('out-%d.txt' % np.random.randint(10**18), 'w', encoding='utf-8')\n",
    "    for p, ex in zip(prediction, data):\n",
    "        p_id, q_id, c_id = ex.id.split('_')[-3:]\n",
    "        writer.write('%s,%s,%s,%f\\n' % (p_id, q_id, c_id, p))\n",
    "    writer.close()\n",
    "\n",
    "def gen_debug_file(data, prediction):\n",
    "    writer = open('./data/output.log', 'w', encoding='utf-8')\n",
    "    cur_pred, cur_choices = [], []\n",
    "    for i, ex in enumerate(data):\n",
    "        if i + 1 == len(data):\n",
    "            cur_pred.append(prediction[i])\n",
    "            cur_choices.append(ex.choice)\n",
    "        if (i > 0 and ex.id[:-1] != data[i - 1].id[:-1]) or (i + 1 == len(data)):\n",
    "            writer.write('Passage: %s\\n' % data[i - 1].passage)\n",
    "            writer.write('Question: %s\\n' % data[i - 1].question)\n",
    "            for idx, choice in enumerate(cur_choices):\n",
    "                writer.write('%s  %f\\n' % (choice, cur_pred[idx]))\n",
    "            writer.write('\\n')\n",
    "            cur_pred, cur_choices = [], []\n",
    "        cur_pred.append(prediction[i])\n",
    "        cur_choices.append(ex.choice)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "def gen_final_submission(data):\n",
    "    import glob\n",
    "    proba_list = []\n",
    "    for f in glob.glob('./out-*.txt'):\n",
    "        print('Process %s...' % f)\n",
    "        lines = open(f, 'r', encoding='utf-8').readlines()\n",
    "        lines = map(lambda s: s.strip(), lines)\n",
    "        lines = list(filter(lambda s: len(s) > 0, lines))\n",
    "        assert len(lines) == len(data)\n",
    "        proba_list.append(lines)\n",
    "    avg_proba, p_q_id = [], []\n",
    "    for i in range(len(data)):\n",
    "        cur_avg_p = np.average([float(p[i].split(',')[-1]) for p in proba_list])\n",
    "        cur_p_q_id = ','.join(data[i].id.split('_')[-3:-1])\n",
    "        if i == 0 or cur_p_q_id != p_q_id[-1]:\n",
    "            avg_proba.append([cur_avg_p])\n",
    "            p_q_id.append(cur_p_q_id)\n",
    "        else:\n",
    "            avg_proba[-1].append(cur_avg_p)\n",
    "    gen_debug_file(data, [p for sublist in avg_proba for p in sublist])\n",
    "    writer = open('answer.txt', 'w', encoding='utf-8')\n",
    "    assert len(avg_proba) == len(p_q_id)\n",
    "    cnt = 0\n",
    "    for probas, cur_p_q_id in zip(avg_proba, p_q_id):\n",
    "        cnt += 1\n",
    "        assert len(probas) > 1\n",
    "        pred_ans = np.argmax(probas)\n",
    "        writer.write('%s,%d' % (cur_p_q_id, pred_ans))\n",
    "        if cnt < len(p_q_id):\n",
    "            writer.write('\\n')\n",
    "    writer.close()\n",
    "    os.system('zip final_output.zip answer.txt')\n",
    "    print('Please submit final_output.zip to codalab.')\n",
    "\n",
    "def eval_based_on_outputs(path):\n",
    "    dev_data = load_data('./data/dev-data-processed.json')\n",
    "    label = [int(ex.label) for ex in dev_data]\n",
    "    gold, cur_gold = [], []\n",
    "    for i, ex in enumerate(dev_data):\n",
    "        if i + 1 == len(dev_data):\n",
    "            cur_gold.append(label[i])\n",
    "        if (i > 0 and ex.id[:-1] != dev_data[i - 1].id[:-1]) or (i + 1 == len(dev_data)):\n",
    "            gy = np.argmax(cur_gold)\n",
    "            gold.append(gy)\n",
    "            cur_gold = []\n",
    "        cur_gold.append(label[i])\n",
    "    prediction = [s.strip() for s in open(path, 'r', encoding='utf-8').readlines() if len(s.strip()) > 0]\n",
    "    prediction = [int(s.split(',')[-1]) for s in prediction]\n",
    "    assert len(prediction) == len(gold)\n",
    "    acc = sum([int(p == g) for p, g in zip(prediction, gold)]) / len(gold)\n",
    "    print('Accuracy on dev_data: %f' % acc)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # build_vocab()\n",
    "    trial_data = load_data('./data/trial-data-processed.json')\n",
    "    train_data = load_data('./data/train-data-processed.json')\n",
    "    dev_data = load_data('./data/dev-data-processed.json')\n",
    "    test_data = load_data('./data/test-data-processed.json')\n",
    "    build_vocab(trial_data + train_data + dev_data + test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from utils import vocab, pos_vocab, ner_vocab, rel_vocab\n",
    "\n",
    "class Example:\n",
    "\n",
    "    def __init__(self, input_dict):\n",
    "        self.id = input_dict['id']\n",
    "        self.passage = input_dict['d_words']\n",
    "        self.question = input_dict['q_words']\n",
    "        self.choice = input_dict['c_words']\n",
    "        self.d_pos = input_dict['d_pos']\n",
    "        self.d_ner = input_dict['d_ner']\n",
    "        self.q_pos = input_dict['q_pos']\n",
    "        assert len(self.q_pos) == len(self.question.split()), (self.q_pos, self.question)\n",
    "        assert len(self.d_pos) == len(self.passage.split())\n",
    "        self.features = np.stack([input_dict['in_q'], input_dict['in_c'], \\\n",
    "                                    input_dict['lemma_in_q'], input_dict['lemma_in_c'], \\\n",
    "                                    input_dict['tf']], 1)\n",
    "        assert len(self.features) == len(self.passage.split())\n",
    "        self.label = input_dict['label']\n",
    "\n",
    "        self.d_tensor = torch.LongTensor([vocab[w] for w in self.passage.split()])\n",
    "        self.q_tensor = torch.LongTensor([vocab[w] for w in self.question.split()])\n",
    "        self.c_tensor = torch.LongTensor([vocab[w] for w in self.choice.split()])\n",
    "        self.d_pos_tensor = torch.LongTensor([pos_vocab[w] for w in self.d_pos])\n",
    "        self.q_pos_tensor = torch.LongTensor([pos_vocab[w] for w in self.q_pos])\n",
    "        self.d_ner_tensor = torch.LongTensor([ner_vocab[w] for w in self.d_ner])\n",
    "        self.features = torch.from_numpy(self.features).type(torch.FloatTensor)\n",
    "        self.p_q_relation = torch.LongTensor([rel_vocab[r] for r in input_dict['p_q_relation']])\n",
    "        self.p_c_relation = torch.LongTensor([rel_vocab[r] for r in input_dict['p_c_relation']])\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Passage: %s\\n Question: %s\\n Answer: %s, Label: %d' % (self.passage, self.question, self.choice, self.label)\n",
    "\n",
    "def _to_indices_and_mask(batch_tensor, need_mask=True):\n",
    "    mx_len = max([t.size(0) for t in batch_tensor])\n",
    "    batch_size = len(batch_tensor)\n",
    "    indices = torch.LongTensor(batch_size, mx_len).fill_(0)\n",
    "    if need_mask:\n",
    "        mask = torch.ByteTensor(batch_size, mx_len).fill_(1)\n",
    "    for i, t in enumerate(batch_tensor):\n",
    "        indices[i, :len(t)].copy_(t)\n",
    "        if need_mask:\n",
    "            mask[i, :len(t)].fill_(0)\n",
    "    if need_mask:\n",
    "        return indices, mask\n",
    "    else:\n",
    "        return indices\n",
    "\n",
    "def _to_feature_tensor(features):\n",
    "    mx_len = max([f.size(0) for f in features])\n",
    "    batch_size = len(features)\n",
    "    f_dim = features[0].size(1)\n",
    "    f_tensor = torch.FloatTensor(batch_size, mx_len, f_dim).fill_(0)\n",
    "    for i, f in enumerate(features):\n",
    "        f_tensor[i, :len(f), :].copy_(f)\n",
    "    return f_tensor\n",
    "\n",
    "def batchify(batch_data):\n",
    "    p, p_mask = _to_indices_and_mask([ex.d_tensor for ex in batch_data])\n",
    "    p_pos = _to_indices_and_mask([ex.d_pos_tensor for ex in batch_data], need_mask=False)\n",
    "    p_ner = _to_indices_and_mask([ex.d_ner_tensor for ex in batch_data], need_mask=False)\n",
    "    p_q_relation = _to_indices_and_mask([ex.p_q_relation for ex in batch_data], need_mask=False)\n",
    "    p_c_relation = _to_indices_and_mask([ex.p_c_relation for ex in batch_data], need_mask=False)\n",
    "    q, q_mask = _to_indices_and_mask([ex.q_tensor for ex in batch_data])\n",
    "    q_pos = _to_indices_and_mask([ex.q_pos_tensor for ex in batch_data], need_mask=False)\n",
    "    choices = [ex.choice.split() for ex in batch_data]\n",
    "    c, c_mask = _to_indices_and_mask([ex.c_tensor for ex in batch_data])\n",
    "    f_tensor = _to_feature_tensor([ex.features for ex in batch_data])\n",
    "    y = torch.FloatTensor([ex.label for ex in batch_data])\n",
    "    return p, p_pos, p_ner, p_mask, q, q_pos, q_mask, c, c_mask, f_tensor, p_q_relation, p_c_relation, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Definitions of model layers/NN modules\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class StackedBRNN(nn.Module):\n",
    "    \"\"\"Stacked Bi-directional RNNs.\n",
    "\n",
    "    Differs from standard PyTorch library in that it has the option to save\n",
    "    and concat the hidden states between layers. (i.e. the output hidden size\n",
    "    for each sequence input is num_layers * hidden_size).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers,\n",
    "                 dropout_rate=0, dropout_output=False, rnn_type=nn.LSTM,\n",
    "                 concat_layers=False, padding=False):\n",
    "        super(StackedBRNN, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.dropout_output = dropout_output\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_layers = num_layers\n",
    "        self.concat_layers = concat_layers\n",
    "        self.rnns = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            input_size = input_size if i == 0 else 2 * hidden_size\n",
    "            self.rnns.append(rnn_type(input_size, hidden_size,\n",
    "                                      num_layers=1,\n",
    "                                      bidirectional=True))\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        \"\"\"Encode either padded or non-padded sequences.\n",
    "\n",
    "        Can choose to either handle or ignore variable length sequences.\n",
    "        Always handle padding in eval.\n",
    "\n",
    "        Args:\n",
    "            x: batch * len * hdim\n",
    "            x_mask: batch * len (1 for padding, 0 for true)\n",
    "        Output:\n",
    "            x_encoded: batch * len * hdim_encoded\n",
    "        \"\"\"\n",
    "        if x_mask.data.sum() == 0:\n",
    "            # No padding necessary.\n",
    "            output = self._forward_unpadded(x, x_mask)\n",
    "        elif self.padding or not self.training:\n",
    "            # Pad if we care or if its during eval.\n",
    "            output = self._forward_padded(x, x_mask)\n",
    "        else:\n",
    "            # We don't care.\n",
    "            output = self._forward_unpadded(x, x_mask)\n",
    "\n",
    "        return output.contiguous()\n",
    "\n",
    "    def _forward_unpadded(self, x, x_mask):\n",
    "        \"\"\"Faster encoding that ignores any padding.\"\"\"\n",
    "        # Transpose batch and sequence dims\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        # Encode all layers\n",
    "        outputs = [x]\n",
    "        for i in range(self.num_layers):\n",
    "            rnn_input = outputs[-1]\n",
    "\n",
    "            # Apply dropout to hidden input\n",
    "            if self.dropout_rate > 0:\n",
    "                rnn_input = F.dropout(rnn_input,\n",
    "                                      p=self.dropout_rate,\n",
    "                                      training=self.training)\n",
    "            # Forward\n",
    "            rnn_output = self.rnns[i](rnn_input)[0]\n",
    "            outputs.append(rnn_output)\n",
    "\n",
    "        # Concat hidden layers\n",
    "        if self.concat_layers:\n",
    "            output = torch.cat(outputs[1:], 2)\n",
    "        else:\n",
    "            output = outputs[-1]\n",
    "\n",
    "        # Transpose back\n",
    "        output = output.transpose(0, 1)\n",
    "\n",
    "        # Dropout on output layer\n",
    "        if self.dropout_output and self.dropout_rate > 0:\n",
    "            output = F.dropout(output,\n",
    "                               p=self.dropout_rate,\n",
    "                               training=self.training)\n",
    "        return output\n",
    "\n",
    "    def _forward_padded(self, x, x_mask):\n",
    "        \"\"\"Slower (significantly), but more precise, encoding that handles\n",
    "        padding.\n",
    "        \"\"\"\n",
    "        # Compute sorted sequence lengths\n",
    "        lengths = x_mask.data.eq(0).long().sum(1).squeeze()\n",
    "        _, idx_sort = torch.sort(lengths, dim=0, descending=True)\n",
    "        _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
    "\n",
    "        lengths = list(lengths[idx_sort])\n",
    "        idx_sort = Variable(idx_sort)\n",
    "        idx_unsort = Variable(idx_unsort)\n",
    "\n",
    "        # Sort x\n",
    "        x = x.index_select(0, idx_sort)\n",
    "\n",
    "        # Transpose batch and sequence dims\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        # Pack it up\n",
    "        rnn_input = nn.utils.rnn.pack_padded_sequence(x, lengths)\n",
    "\n",
    "        # Encode all layers\n",
    "        outputs = [rnn_input]\n",
    "        for i in range(self.num_layers):\n",
    "            rnn_input = outputs[-1]\n",
    "\n",
    "            # Apply dropout to input\n",
    "            if self.dropout_rate > 0:\n",
    "                dropout_input = F.dropout(rnn_input.data,\n",
    "                                          p=self.dropout_rate,\n",
    "                                          training=self.training)\n",
    "                rnn_input = nn.utils.rnn.PackedSequence(dropout_input,\n",
    "                                                        rnn_input.batch_sizes)\n",
    "            outputs.append(self.rnns[i](rnn_input)[0])\n",
    "\n",
    "        # Unpack everything\n",
    "        for i, o in enumerate(outputs[1:], 1):\n",
    "            outputs[i] = nn.utils.rnn.pad_packed_sequence(o)[0]\n",
    "\n",
    "        # Concat hidden layers or take final\n",
    "        if self.concat_layers:\n",
    "            output = torch.cat(outputs[1:], 2)\n",
    "        else:\n",
    "            output = outputs[-1]\n",
    "\n",
    "        # Transpose and unsort\n",
    "        output = output.transpose(0, 1)\n",
    "        output = output.index_select(0, idx_unsort)\n",
    "\n",
    "        # Pad up to original batch sequence length\n",
    "        if output.size(1) != x_mask.size(1):\n",
    "            padding = torch.zeros(output.size(0),\n",
    "                                  x_mask.size(1) - output.size(1),\n",
    "                                  output.size(2)).type(output.data.type())\n",
    "            output = torch.cat([output, Variable(padding)], 1)\n",
    "\n",
    "        # Dropout on output layer\n",
    "        if self.dropout_output and self.dropout_rate > 0:\n",
    "            output = F.dropout(output,\n",
    "                               p=self.dropout_rate,\n",
    "                               training=self.training)\n",
    "        return output\n",
    "\n",
    "\n",
    "class SeqAttnMatch(nn.Module):\n",
    "    \"\"\"Given sequences X and Y, match sequence Y to each element in X.\n",
    "\n",
    "    * o_i = sum(alpha_j * y_j) for i in X\n",
    "    * alpha_j = softmax(y_j * x_i)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, identity=False):\n",
    "        super(SeqAttnMatch, self).__init__()\n",
    "        if not identity:\n",
    "            self.linear = nn.Linear(input_size, input_size)\n",
    "        else:\n",
    "            self.linear = None\n",
    "\n",
    "    def forward(self, x, y, y_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch * len1 * hdim\n",
    "            y: batch * len2 * hdim\n",
    "            y_mask: batch * len2 (1 for padding, 0 for true)\n",
    "        Output:\n",
    "            matched_seq: batch * len1 * hdim\n",
    "        \"\"\"\n",
    "        # Project vectors\n",
    "        if self.linear:\n",
    "            x_proj = self.linear(x.view(-1, x.size(2))).view(x.size())\n",
    "            x_proj = F.relu(x_proj)\n",
    "            y_proj = self.linear(y.view(-1, y.size(2))).view(y.size())\n",
    "            y_proj = F.relu(y_proj)\n",
    "        else:\n",
    "            x_proj = x\n",
    "            y_proj = y\n",
    "\n",
    "        # Compute scores\n",
    "        scores = x_proj.bmm(y_proj.transpose(2, 1))\n",
    "\n",
    "        # Mask padding\n",
    "        y_mask = y_mask.unsqueeze(1).expand(scores.size())\n",
    "        scores.data.masked_fill_(y_mask.data, -float('inf'))\n",
    "\n",
    "        # Normalize with softmax\n",
    "        alpha_flat = F.softmax(scores.view(-1, y.size(1)))\n",
    "        alpha = alpha_flat.view(-1, x.size(1), y.size(1))\n",
    "\n",
    "        # Take weighted average\n",
    "        matched_seq = alpha.bmm(y)\n",
    "        return matched_seq\n",
    "\n",
    "\n",
    "class BilinearSeqAttn(nn.Module):\n",
    "    \"\"\"A bilinear attention layer over a sequence X w.r.t y:\n",
    "\n",
    "    * o_i = softmax(x_i'Wy) for x_i in X.\n",
    "\n",
    "    Optionally don't normalize output weights.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_size, y_size, identity=False, normalize=True):\n",
    "        super(BilinearSeqAttn, self).__init__()\n",
    "        self.normalize = normalize\n",
    "\n",
    "        # If identity is true, we just use a dot product without transformation.\n",
    "        if not identity:\n",
    "            self.linear = nn.Linear(y_size, x_size)\n",
    "        else:\n",
    "            self.linear = None\n",
    "\n",
    "    def forward(self, x, y, x_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch * len * hdim1\n",
    "            y: batch * hdim2\n",
    "            x_mask: batch * len (1 for padding, 0 for true)\n",
    "        Output:\n",
    "            alpha = batch * len\n",
    "        \"\"\"\n",
    "        Wy = self.linear(y) if self.linear is not None else y\n",
    "        xWy = x.bmm(Wy.unsqueeze(2)).squeeze(2)\n",
    "        xWy.data.masked_fill_(x_mask.data, -float('inf'))\n",
    "        if self.normalize:\n",
    "            alpha = F.softmax(xWy)\n",
    "        else:\n",
    "            alpha = xWy.exp()\n",
    "        return alpha\n",
    "\n",
    "\n",
    "class LinearSeqAttn(nn.Module):\n",
    "    \"\"\"Self attention over a sequence:\n",
    "\n",
    "    * o_i = softmax(Wx_i) for x_i in X.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearSeqAttn, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch * len * hdim\n",
    "            x_mask: batch * len (1 for padding, 0 for true)\n",
    "        Output:\n",
    "            alpha: batch * len\n",
    "        \"\"\"\n",
    "        x_flat = x.view(-1, x.size(-1))\n",
    "        scores = self.linear(x_flat).view(x.size(0), x.size(1))\n",
    "        scores.data.masked_fill_(x_mask.data, -float('inf'))\n",
    "        alpha = F.softmax(scores)\n",
    "        return alpha\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Functional\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def uniform_weights(x, x_mask):\n",
    "    \"\"\"Return uniform weights over non-masked x (a sequence of vectors).\n",
    "\n",
    "    Args:\n",
    "        x: batch * len * hdim\n",
    "        x_mask: batch * len (1 for padding, 0 for true)\n",
    "    Output:\n",
    "        x_avg: batch * hdim\n",
    "    \"\"\"\n",
    "    alpha = Variable(torch.ones(x.size(0), x.size(1)))\n",
    "    if x.data.is_cuda:\n",
    "        alpha = alpha.cuda()\n",
    "    alpha = alpha * x_mask.eq(0).float()\n",
    "    alpha = alpha / alpha.sum(1).expand(alpha.size())\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def weighted_avg(x, weights):\n",
    "    \"\"\"Return a weighted average of x (a sequence of vectors).\n",
    "\n",
    "    Args:\n",
    "        x: batch * len * hdim\n",
    "        weights: batch * len, sum(dim = 1) = 1\n",
    "    Output:\n",
    "        x_avg: batch * hdim\n",
    "    \"\"\"\n",
    "    return weights.unsqueeze(1).bmm(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import layers\n",
    "from utils import vocab, pos_vocab, ner_vocab, rel_vocab\n",
    "\n",
    "class TriAN(nn.Module):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(TriAN, self).__init__()\n",
    "        self.args = args\n",
    "        self.embedding_dim = 300\n",
    "        self.embedding = nn.Embedding(len(vocab), self.embedding_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.fill_(0)\n",
    "        self.embedding.weight.data[:2].normal_(0, 0.1)\n",
    "        self.pos_embedding = nn.Embedding(len(pos_vocab), args.pos_emb_dim, padding_idx=0)\n",
    "        self.pos_embedding.weight.data.normal_(0, 0.1)\n",
    "        self.ner_embedding = nn.Embedding(len(ner_vocab), args.ner_emb_dim, padding_idx=0)\n",
    "        self.ner_embedding.weight.data.normal_(0, 0.1)\n",
    "        self.rel_embedding = nn.Embedding(len(rel_vocab), args.rel_emb_dim, padding_idx=0)\n",
    "        self.rel_embedding.weight.data.normal_(0, 0.1)\n",
    "        self.RNN_TYPES = {'lstm': nn.LSTM, 'gru': nn.GRU}\n",
    "\n",
    "        self.p_q_emb_match = layers.SeqAttnMatch(self.embedding_dim)\n",
    "        self.c_q_emb_match = layers.SeqAttnMatch(self.embedding_dim)\n",
    "        self.c_p_emb_match = layers.SeqAttnMatch(self.embedding_dim)\n",
    "\n",
    "        # Input size to RNN: word emb + question emb + pos emb + ner emb + manual features\n",
    "        doc_input_size = 2 * self.embedding_dim + args.pos_emb_dim + args.ner_emb_dim + 5 + 2 * args.rel_emb_dim\n",
    "\n",
    "        # RNN document encoder\n",
    "        self.doc_rnn = layers.StackedBRNN(\n",
    "            input_size=doc_input_size,\n",
    "            hidden_size=args.hidden_size,\n",
    "            num_layers=args.doc_layers,\n",
    "            dropout_rate=0,\n",
    "            dropout_output=args.dropout_rnn_output,\n",
    "            concat_layers=False,\n",
    "            rnn_type=self.RNN_TYPES[args.rnn_type],\n",
    "            padding=args.rnn_padding)\n",
    "\n",
    "        # RNN question encoder: word emb + pos emb\n",
    "        qst_input_size = self.embedding_dim + args.pos_emb_dim\n",
    "        self.question_rnn = layers.StackedBRNN(\n",
    "            input_size=qst_input_size,\n",
    "            hidden_size=args.hidden_size,\n",
    "            num_layers=1,\n",
    "            dropout_rate=0,\n",
    "            dropout_output=args.dropout_rnn_output,\n",
    "            concat_layers=False,\n",
    "            rnn_type=self.RNN_TYPES[args.rnn_type],\n",
    "            padding=args.rnn_padding)\n",
    "\n",
    "        # RNN answer encoder\n",
    "        choice_input_size = 3 * self.embedding_dim\n",
    "        self.choice_rnn = layers.StackedBRNN(\n",
    "            input_size=choice_input_size,\n",
    "            hidden_size=args.hidden_size,\n",
    "            num_layers=1,\n",
    "            dropout_rate=0,\n",
    "            dropout_output=args.dropout_rnn_output,\n",
    "            concat_layers=False,\n",
    "            rnn_type=self.RNN_TYPES[args.rnn_type],\n",
    "            padding=args.rnn_padding)\n",
    "\n",
    "        # Output sizes of rnn encoders\n",
    "        doc_hidden_size = 2 * args.hidden_size\n",
    "        question_hidden_size = 2 * args.hidden_size\n",
    "        choice_hidden_size = 2 * args.hidden_size\n",
    "\n",
    "        # Answer merging\n",
    "        self.c_self_attn = layers.LinearSeqAttn(choice_hidden_size)\n",
    "        self.q_self_attn = layers.LinearSeqAttn(question_hidden_size)\n",
    "\n",
    "        self.p_q_attn = layers.BilinearSeqAttn(x_size=doc_hidden_size, y_size=question_hidden_size)\n",
    "\n",
    "        self.p_c_bilinear = nn.Linear(doc_hidden_size, choice_hidden_size)\n",
    "        self.q_c_bilinear = nn.Linear(question_hidden_size, choice_hidden_size)\n",
    "\n",
    "    def forward(self, p, p_pos, p_ner, p_mask, q, q_pos, q_mask, c, c_mask, f_tensor, p_q_relation, p_c_relation):\n",
    "        p_emb, q_emb, c_emb = self.embedding(p), self.embedding(q), self.embedding(c)\n",
    "        p_pos_emb, p_ner_emb, q_pos_emb = self.pos_embedding(p_pos), self.ner_embedding(p_ner), self.pos_embedding(q_pos)\n",
    "        p_q_rel_emb, p_c_rel_emb = self.rel_embedding(p_q_relation), self.rel_embedding(p_c_relation)\n",
    "\n",
    "        # Dropout on embeddings\n",
    "        if self.args.dropout_emb > 0:\n",
    "            p_emb = nn.functional.dropout(p_emb, p=self.args.dropout_emb, training=self.training)\n",
    "            q_emb = nn.functional.dropout(q_emb, p=self.args.dropout_emb, training=self.training)\n",
    "            c_emb = nn.functional.dropout(c_emb, p=self.args.dropout_emb, training=self.training)\n",
    "            p_pos_emb = nn.functional.dropout(p_pos_emb, p=self.args.dropout_emb, training=self.training)\n",
    "            p_ner_emb = nn.functional.dropout(p_ner_emb, p=self.args.dropout_emb, training=self.training)\n",
    "            q_pos_emb = nn.functional.dropout(q_pos_emb, p=self.args.dropout_emb, training=self.training)\n",
    "            p_q_rel_emb = nn.functional.dropout(p_q_rel_emb, p=self.args.dropout_emb, training=self.training)\n",
    "            p_c_rel_emb = nn.functional.dropout(p_c_rel_emb, p=self.args.dropout_emb, training=self.training)\n",
    "\n",
    "        p_q_weighted_emb = self.p_q_emb_match(p_emb, q_emb, q_mask)\n",
    "        c_q_weighted_emb = self.c_q_emb_match(c_emb, q_emb, q_mask)\n",
    "        c_p_weighted_emb = self.c_p_emb_match(c_emb, p_emb, p_mask)\n",
    "        p_q_weighted_emb = nn.functional.dropout(p_q_weighted_emb, p=self.args.dropout_emb, training=self.training)\n",
    "        c_q_weighted_emb = nn.functional.dropout(c_q_weighted_emb, p=self.args.dropout_emb, training=self.training)\n",
    "        c_p_weighted_emb = nn.functional.dropout(c_p_weighted_emb, p=self.args.dropout_emb, training=self.training)\n",
    "        # print('p_q_weighted_emb', p_q_weighted_emb.size())\n",
    "\n",
    "        p_rnn_input = torch.cat([p_emb, p_q_weighted_emb, p_pos_emb, p_ner_emb, f_tensor, p_q_rel_emb, p_c_rel_emb], dim=2)\n",
    "        c_rnn_input = torch.cat([c_emb, c_q_weighted_emb, c_p_weighted_emb], dim=2)\n",
    "        q_rnn_input = torch.cat([q_emb, q_pos_emb], dim=2)\n",
    "        # print('p_rnn_input', p_rnn_input.size())\n",
    "\n",
    "        p_hiddens = self.doc_rnn(p_rnn_input, p_mask)\n",
    "        c_hiddens = self.choice_rnn(c_rnn_input, c_mask)\n",
    "        q_hiddens = self.question_rnn(q_rnn_input, q_mask)\n",
    "        # print('p_hiddens', p_hiddens.size())\n",
    "\n",
    "        q_merge_weights = self.q_self_attn(q_hiddens, q_mask)\n",
    "        q_hidden = layers.weighted_avg(q_hiddens, q_merge_weights)\n",
    "\n",
    "        p_merge_weights = self.p_q_attn(p_hiddens, q_hidden, p_mask)\n",
    "        # [batch_size, 2*hidden_size]\n",
    "        p_hidden = layers.weighted_avg(p_hiddens, p_merge_weights)\n",
    "        # print('p_hidden', p_hidden.size())\n",
    "\n",
    "        c_merge_weights = self.c_self_attn(c_hiddens, c_mask)\n",
    "        # [batch_size, 2*hidden_size]\n",
    "        c_hidden = layers.weighted_avg(c_hiddens, c_merge_weights)\n",
    "        # print('c_hidden', c_hidden.size())\n",
    "\n",
    "        logits = torch.sum(self.p_c_bilinear(p_hidden) * c_hidden, dim=-1)\n",
    "        logits += torch.sum(self.q_c_bilinear(q_hidden) * c_hidden, dim=-1)\n",
    "        proba = F.sigmoid(logits)\n",
    "        # print('proba', proba.size())\n",
    "\n",
    "        return proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import copy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import numpy as np\n",
    "\n",
    "from utils import vocab\n",
    "from doc import batchify\n",
    "from trian import TriAN\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.batch_size = args.batch_size\n",
    "        self.finetune_topk = args.finetune_topk\n",
    "        self.lr = args.lr\n",
    "        self.use_cuda = (args.use_cuda == True) and torch.cuda.is_available()\n",
    "        print('Use cuda:', self.use_cuda)\n",
    "        if self.use_cuda:\n",
    "            torch.cuda.set_device(int(args.gpu))\n",
    "        self.network = TriAN(args)\n",
    "        self.init_optimizer()\n",
    "        if args.pretrained:\n",
    "            print('Load pretrained model from %s...' % args.pretrained)\n",
    "            self.load(args.pretrained)\n",
    "        else:\n",
    "            self.load_embeddings(vocab.tokens(), args.embedding_file)\n",
    "        self.network.register_buffer('fixed_embedding', self.network.embedding.weight.data[self.finetune_topk:].clone())\n",
    "        if self.use_cuda:\n",
    "            self.network.cuda()\n",
    "        print(self.network)\n",
    "        self._report_num_trainable_parameters()\n",
    "\n",
    "    def _report_num_trainable_parameters(self):\n",
    "        num_parameters = 0\n",
    "        for p in self.network.parameters():\n",
    "            if p.requires_grad:\n",
    "                sz = list(p.size())\n",
    "                if sz[0] == len(vocab):\n",
    "                    sz[0] = self.finetune_topk\n",
    "                num_parameters += np.prod(sz)\n",
    "        print('Number of parameters: ', num_parameters)\n",
    "\n",
    "    def train(self, train_data):\n",
    "        self.network.train()\n",
    "        self.updates = 0\n",
    "        iter_cnt, num_iter = 0, (len(train_data) + self.batch_size - 1) // self.batch_size\n",
    "        for batch_input in self._iter_data(train_data):\n",
    "            feed_input = [x for x in batch_input[:-1]]\n",
    "            y = batch_input[-1]\n",
    "            pred_proba = self.network(*feed_input)\n",
    "\n",
    "            loss = F.binary_cross_entropy(pred_proba, y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm(self.network.parameters(), self.args.grad_clipping)\n",
    "\n",
    "            # Update parameters\n",
    "            self.optimizer.step()\n",
    "            self.network.embedding.weight.data[self.finetune_topk:] = self.network.fixed_embedding\n",
    "            self.updates += 1\n",
    "            iter_cnt += 1\n",
    "\n",
    "            if self.updates % 20 == 0:\n",
    "                print('Iter: %d/%d, Loss: %f' % (iter_cnt, num_iter, loss.data[0]))\n",
    "        self.scheduler.step()\n",
    "        print('LR:', self.scheduler.get_lr()[0])\n",
    "\n",
    "    def evaluate(self, dev_data, debug=False, eval_train=False):\n",
    "        if len(dev_data) == 0:\n",
    "            return -1.0\n",
    "        self.network.eval()\n",
    "        correct, total, prediction, gold = 0, 0, [], []\n",
    "        dev_data = sorted(dev_data, key=lambda ex: ex.id)\n",
    "        for batch_input in self._iter_data(dev_data):\n",
    "            feed_input = [x for x in batch_input[:-1]]\n",
    "            y = batch_input[-1].data.cpu().numpy()\n",
    "            pred_proba = self.network(*feed_input)\n",
    "            pred_proba = pred_proba.data.cpu()\n",
    "            prediction += list(pred_proba)\n",
    "            gold += [int(label) for label in y]\n",
    "            assert(len(prediction) == len(gold))\n",
    "\n",
    "        if eval_train:\n",
    "            prediction = [1 if p > 0.5 else 0 for p in prediction]\n",
    "            acc = sum([1 if y1 == y2 else 0 for y1, y2 in zip(prediction, gold)]) / len(gold)\n",
    "            return acc\n",
    "\n",
    "        cur_pred, cur_gold, cur_choices = [], [], []\n",
    "        if debug:\n",
    "            writer = open('./data/output.log', 'w', encoding='utf-8')\n",
    "        for i, ex in enumerate(dev_data):\n",
    "            if i + 1 == len(dev_data):\n",
    "                cur_pred.append(prediction[i])\n",
    "                cur_gold.append(gold[i])\n",
    "                cur_choices.append(ex.choice)\n",
    "            if (i > 0 and ex.id[:-1] != dev_data[i - 1].id[:-1]) or (i + 1 == len(dev_data)):\n",
    "                py, gy = np.argmax(cur_pred), np.argmax(cur_gold)\n",
    "                if debug:\n",
    "                    writer.write('Passage: %s\\n' % dev_data[i - 1].passage)\n",
    "                    writer.write('Question: %s\\n' % dev_data[i - 1].question)\n",
    "                    for idx, choice in enumerate(cur_choices):\n",
    "                        writer.write('*' if idx == gy else ' ')\n",
    "                        writer.write('%s  %f\\n' % (choice, cur_pred[idx]))\n",
    "                    writer.write('\\n')\n",
    "                if py == gy:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                cur_pred, cur_gold, cur_choices = [], [], []\n",
    "            cur_pred.append(prediction[i])\n",
    "            cur_gold.append(gold[i])\n",
    "            cur_choices.append(ex.choice)\n",
    "\n",
    "        acc = 1.0 * correct / total\n",
    "        if debug:\n",
    "            writer.write('Accuracy: %f\\n' % acc)\n",
    "            writer.close()\n",
    "        return acc\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        # DO NOT SHUFFLE test_data\n",
    "        self.network.eval()\n",
    "        prediction = []\n",
    "        for batch_input in self._iter_data(test_data):\n",
    "            feed_input = [x for x in batch_input[:-1]]\n",
    "            pred_proba = self.network(*feed_input)\n",
    "            pred_proba = pred_proba.data.cpu()\n",
    "            prediction += list(pred_proba)\n",
    "        return prediction\n",
    "\n",
    "    def _iter_data(self, data):\n",
    "        num_iter = (len(data) + self.batch_size - 1) // self.batch_size\n",
    "        for i in range(num_iter):\n",
    "            start_idx = i * self.batch_size\n",
    "            batch_data = data[start_idx:(start_idx + self.batch_size)]\n",
    "            batch_input = batchify(batch_data)\n",
    "\n",
    "            # Transfer to GPU\n",
    "            if self.use_cuda:\n",
    "                batch_input = [Variable(x.cuda(async=True)) for x in batch_input]\n",
    "            else:\n",
    "                batch_input = [Variable(x) for x in batch_input]\n",
    "            yield batch_input\n",
    "\n",
    "    def load_embeddings(self, words, embedding_file):\n",
    "        \"\"\"Load pretrained embeddings for a given list of words, if they exist.\n",
    "\n",
    "        Args:\n",
    "            words: iterable of tokens. Only those that are indexed in the\n",
    "              dictionary are kept.\n",
    "            embedding_file: path to text file of embeddings, space separated.\n",
    "        \"\"\"\n",
    "        words = {w for w in words if w in vocab}\n",
    "        logger.info('Loading pre-trained embeddings for %d words from %s' %\n",
    "                    (len(words), embedding_file))\n",
    "        embedding = self.network.embedding.weight.data\n",
    "\n",
    "        # When normalized, some words are duplicated. (Average the embeddings).\n",
    "        vec_counts = {}\n",
    "        with open(embedding_file) as f:\n",
    "            for line in f:\n",
    "                parsed = line.rstrip().split(' ')\n",
    "                assert(len(parsed) == embedding.size(1) + 1)\n",
    "                w = vocab.normalize(parsed[0])\n",
    "                if w in words:\n",
    "                    vec = torch.Tensor([float(i) for i in parsed[1:]])\n",
    "                    if w not in vec_counts:\n",
    "                        vec_counts[w] = 1\n",
    "                        embedding[vocab[w]].copy_(vec)\n",
    "                    else:\n",
    "                        logging.warning('WARN: Duplicate embedding found for %s' % w)\n",
    "                        vec_counts[w] = vec_counts[w] + 1\n",
    "                        embedding[vocab[w]].add_(vec)\n",
    "\n",
    "        for w, c in vec_counts.items():\n",
    "            embedding[vocab[w]].div_(c)\n",
    "\n",
    "        logger.info('Loaded %d embeddings (%.2f%%)' %\n",
    "                    (len(vec_counts), 100 * len(vec_counts) / len(words)))\n",
    "\n",
    "    def init_optimizer(self):\n",
    "        parameters = [p for p in self.network.parameters() if p.requires_grad]\n",
    "        if self.args.optimizer == 'sgd':\n",
    "            self.optimizer = optim.SGD(parameters, self.lr,\n",
    "                                       momentum=0.4,\n",
    "                                       weight_decay=0)\n",
    "        elif self.args.optimizer == 'adamax':\n",
    "            self.optimizer = optim.Adamax(parameters,\n",
    "                                        lr=self.lr,\n",
    "                                        weight_decay=0)\n",
    "        else:\n",
    "            raise RuntimeError('Unsupported optimizer: %s' %\n",
    "                               self.args.optimizer)\n",
    "        self.scheduler = lr_scheduler.MultiStepLR(self.optimizer, milestones=[10, 15], gamma=0.5)\n",
    "\n",
    "    def save(self, ckt_path):\n",
    "        state_dict = copy.copy(self.network.state_dict())\n",
    "        if 'fixed_embedding' in state_dict:\n",
    "            state_dict.pop('fixed_embedding')\n",
    "        params = {'state_dict': state_dict}\n",
    "        torch.save(params, ckt_path)\n",
    "\n",
    "    def load(self, ckt_path):\n",
    "        logger.info('Loading model %s' % ckt_path)\n",
    "        saved_params = torch.load(ckt_path, map_location=lambda storage, loc: storage)\n",
    "        state_dict = saved_params['state_dict']\n",
    "        return self.network.load_state_dict(state_dict)\n",
    "\n",
    "    def cuda(self):\n",
    "        self.use_cuda = True\n",
    "        self.network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load vocabulary from ./data/vocab...\n",
      "Vocabulary size: 33382\n",
      "Load pos vocabulary from ./data/pos_vocab...\n",
      "POS vocabulary size: 51\n",
      "Load ner vocabulary from ./data/ner_vocab...\n",
      "NER vocabulary size: 20\n",
      "Load relation vocabulary from ./data/rel_vocab...\n",
      "Rel vocabulary size: 39\n",
      "Load 19462 examples from ./data/train-data-processed.json...\n",
      "Load 1020 examples from ./data/trial-data-processed.json...\n",
      "Load 2822 examples from ./data/dev-data-processed.json...\n",
      "Use cuda: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:WARN: Duplicate embedding found for ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriAN(\n",
      "  (embedding): Embedding(33382, 300, padding_idx=0)\n",
      "  (pos_embedding): Embedding(51, 12, padding_idx=0)\n",
      "  (ner_embedding): Embedding(20, 8, padding_idx=0)\n",
      "  (rel_embedding): Embedding(39, 10, padding_idx=0)\n",
      "  (p_q_emb_match): SeqAttnMatch(\n",
      "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
      "  )\n",
      "  (c_q_emb_match): SeqAttnMatch(\n",
      "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
      "  )\n",
      "  (c_p_emb_match): SeqAttnMatch(\n",
      "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
      "  )\n",
      "  (doc_rnn): StackedBRNN(\n",
      "    (rnns): ModuleList(\n",
      "      (0): LSTM(645, 96, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (question_rnn): StackedBRNN(\n",
      "    (rnns): ModuleList(\n",
      "      (0): LSTM(312, 96, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (choice_rnn): StackedBRNN(\n",
      "    (rnns): ModuleList(\n",
      "      (0): LSTM(900, 96, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (c_self_attn): LinearSeqAttn(\n",
      "    (linear): Linear(in_features=192, out_features=1, bias=True)\n",
      "  )\n",
      "  (q_self_attn): LinearSeqAttn(\n",
      "    (linear): Linear(in_features=192, out_features=1, bias=True)\n",
      "  )\n",
      "  (p_q_attn): BilinearSeqAttn(\n",
      "    (linear): Linear(in_features=192, out_features=192, bias=True)\n",
      "  )\n",
      "  (p_c_bilinear): Linear(in_features=192, out_features=192, bias=True)\n",
      "  (q_c_bilinear): Linear(in_features=192, out_features=192, bias=True)\n",
      ")\n",
      "Number of parameters:  2038584\n",
      "Trained model will be saved to ./checkpoint/1234-2018-06-29T11:46:12.040791.mdl\n",
      "Epoch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/niranjan/Data Science/INKERS/Project -1/Project-Final/layers.py:197: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alpha_flat = F.softmax(scores.view(-1, y.size(1)))\n",
      "/media/niranjan/Data Science/INKERS/Project -1/Project-Final/layers.py:263: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alpha = F.softmax(scores)\n",
      "/media/niranjan/Data Science/INKERS/Project -1/Project-Final/layers.py:236: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alpha = F.softmax(xWy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev accuracy: 0.508859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/niranjan/Data Science/INKERS/Project -1/Project-Final/model.py:63: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(self.network.parameters(), self.args.grad_clipping)\n",
      "/media/niranjan/Data Science/INKERS/Project -1/Project-Final/model.py:72: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  print('Iter: %d/%d, Loss: %f' % (iter_cnt, num_iter, loss.data[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 20/641, Loss: 0.698544\n",
      "Iter: 40/641, Loss: 0.717111\n",
      "Iter: 60/641, Loss: 0.638708\n",
      "Iter: 80/641, Loss: 0.670520\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from utils import load_data, build_vocab\n",
    "from config import args\n",
    "from model import Model\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    build_vocab()\n",
    "    train_data = load_data('./data/train-data-processed.json')\n",
    "    train_data += load_data('./data/trial-data-processed.json')\n",
    "    dev_data = load_data('./data/dev-data-processed.json')\n",
    "    if args.test_mode:\n",
    "        # use validation data as training data\n",
    "        train_data += dev_data\n",
    "        dev_data = []\n",
    "    model = Model(args)\n",
    "\n",
    "    best_dev_acc = 0.0\n",
    "    os.makedirs('./checkpoint', exist_ok=True)\n",
    "    checkpoint_path = './checkpoint/%d-%s.mdl' % (args.seed, datetime.now().isoformat())\n",
    "    print('Trained model will be saved to %s' % checkpoint_path)\n",
    "\n",
    "    for i in range(args.epoch):\n",
    "        print('Epoch %d...' % i)\n",
    "        if i == 0:\n",
    "            dev_acc = model.evaluate(dev_data)\n",
    "            print('Dev accuracy: %f' % dev_acc)\n",
    "        start_time = time.time()\n",
    "        np.random.shuffle(train_data)\n",
    "        cur_train_data = train_data\n",
    "\n",
    "        model.train(cur_train_data)\n",
    "        train_acc = model.evaluate(train_data[:2000], debug=False, eval_train=True)\n",
    "        print('Train accuracy: %f' % train_acc)\n",
    "        dev_acc = model.evaluate(dev_data, debug=True)\n",
    "        print('Dev accuracy: %f' % dev_acc)\n",
    "\n",
    "        if dev_acc > best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            os.system('mv ./data/output.log ./data/best-dev.log')\n",
    "            model.save(checkpoint_path)\n",
    "        elif args.test_mode:\n",
    "            model.save(checkpoint_path)\n",
    "        print('Epoch %d use %d seconds.' % (i, time.time() - start_time))\n",
    "\n",
    "    print('Best dev accuracy: %f' % best_dev_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Play with Pre-Trained Model.. \n",
    "from config import args\n",
    "from utils import load_data, build_vocab, gen_submission, gen_final_submission, eval_based_on_outputs\n",
    "from model import Model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if not args.pretrained:\n",
    "        print('No pretrained model specified.')\n",
    "        exit(0)\n",
    "    build_vocab()\n",
    "\n",
    "    if args.test_mode:\n",
    "        dev_data = load_data('./data/test-data-processed.json')\n",
    "    else:\n",
    "        dev_data = load_data('./data/dev-data-processed.json')\n",
    "    model_path_list = args.pretrained.split(',')\n",
    "    for model_path in model_path_list:\n",
    "        print('Load model from %s...' % model_path)\n",
    "        args.pretrained = model_path\n",
    "        model = Model(args)\n",
    "\n",
    "        # evaluate on development dataset\n",
    "        dev_acc = model.evaluate(dev_data)\n",
    "        print('dev accuracy: %f' % dev_acc)\n",
    "\n",
    "        # generate submission zip file for Codalab\n",
    "        prediction = model.predict(dev_data)\n",
    "        gen_submission(dev_data, prediction)\n",
    "\n",
    "    gen_final_submission(dev_data)\n",
    "    if not args.test_mode:\n",
    "        eval_based_on_outputs('./answer.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to RUN\n",
    "you Train model by simply Running python3 src/main.py --gpu 0 in commandline\n",
    "\n",
    "To Run in Jupyter Notebook, a Details Code for Producing the Results are Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
